---
title: "translatR"
output: github_document
---


Lightweight tools for translation tasks with MXNet R.

Inspiration taken from the [AWS Sockeye](https://github.com/awslabs/sockeye) project. 

## Getting started

Prepare data using WMT Europarl using `Preproc_euro.Rmd`. Creates a source and target matrix of word indices along with the associated dictionnary. Data preparation mainly relying on `data.table` and `stringi` packages. 

A RNN encoder-decoder training demo is provided in `NLP_rnn.Rmd` and and CNN-RNN architecture is shown in `NLP_cnn_rnn.Rmd`. 


## Performance

Performance during training is tracked using perplexity. Once a training is completed, the above scripts show how to perform a batch inference on a test test, more specifically the a WMT official test set. [sacreBLEU](https://github.com/mjpost/sacreBLEU) is then used to compute the BLEU score, providing a clear comparison point to the metric typically found in publications. 

## Features: 

#### Encoders: 

- Bidirectional RNN encoders (LSTM and GRU). 
- Convolutional encoder with residual gates. 

#### Decoders: 

- RNN (LSTM and GRU)

#### Attention: 

Arhcitectures are fully attentioned based. All information is passed from the encoder to the decoder from the encoded sequences (RNN hidden layers are not carry forward from the encoder to the decoder). 

Attention modules are defined in `attention.R`. Three attention approaches are supported, all described in Luong et al, 2015: 

 - Bilinear (``attn_bilinear`)
 - Dot  (`attn_dot`)
 - MLP (`attn_MLP`)

The decoder network takes an attention module as a parameter along with an encoder graph. All attentions modules are implemented using the query-key-value approach.   

# To do: 

 - Test multi-GPU support
 - More efficient data preprocessing to handle larger scale tasks (currently works fine up to around 4M parralel sequences).
 - Support for bucketing
 - Positional embedding
 - Transformer encoder-decoderr
 - Encoder and decoder self-attention
 - Beam search

Tutorial to be added to [Examples of application of RNN](https://jeremiedb.github.io/mxnet_R_bucketing/index.html). 
